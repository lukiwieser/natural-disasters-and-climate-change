{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load and format the temperature anomaly data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "outputs": [],
   "source": [
    "PATH_RAW_TEMP_DATA_FOLDER = 'data/raw/temperature/'\n",
    "PATH_PROCESSED_TEMP_DATA_FOLDER = 'data/processed/temperature/'\n",
    "PATH_COUNTRIES_LAND_FOLDER = 'countries-land/'\n",
    "PATH_REGIONS_LAND_FOLDER = 'regions-land/'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "outputs": [],
   "source": [
    "PATH_COUNTRIES_LIST_FILE = 'temp-countries-list.csv'\n",
    "PATH_UN_COUNTRY_CODES_FILE = \"data/raw/country-codes/un-country-codes.csv\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Country ISO-alpha3\n",
      "0       Afghanistan        AFG\n",
      "1     Åland Islands        ALA\n",
      "2           Albania        ALB\n",
      "3           Algeria        DZA\n",
      "4    American Samoa        ASM\n",
      "..              ...        ...\n",
      "228  Virgin Islands        VIR\n",
      "229  Western Sahara        ESH\n",
      "230           Yemen        YEM\n",
      "231          Zambia        ZMB\n",
      "232        Zimbabwe        ZWE\n",
      "\n",
      "[233 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Todo: remove loading temp_countries from processed data when combining jupyter notebooks\n",
    "temp_countries: pd.DataFrame = pd.read_csv(PATH_PROCESSED_TEMP_DATA_FOLDER + PATH_COUNTRIES_LIST_FILE, sep=',')\n",
    "print(temp_countries)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load temp-land-country data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "outputs": [
    {
     "data": {
      "text/plain": "  country_code country_name  year month  monthly_anomaly  monthly_unc  \\\n0          AFG  Afghanistan  1848     5           -0.297        2.037   \n1          AFG  Afghanistan  1848     6           -0.796        2.136   \n2          AFG  Afghanistan  1848     7           -0.113        1.937   \n3          AFG  Afghanistan  1848     8           -0.462        1.937   \n4          AFG  Afghanistan  1848     9           -1.272        1.865   \n\n   annual_anomaly  annual_unc  five_year_anomaly  five_year_unc  \\\n0             NaN         NaN                NaN            NaN   \n1             NaN         NaN                NaN            NaN   \n2          -0.777       0.639                NaN            NaN   \n3          -0.743       0.644                NaN            NaN   \n4          -0.676       0.669                NaN            NaN   \n\n   ten_year_anomaly  ten_year_unc  twenty_year_anomaly  twenty_year_unc  \n0               NaN           NaN                  NaN              NaN  \n1               NaN           NaN                  NaN              NaN  \n2               NaN           NaN                  NaN              NaN  \n3               NaN           NaN                  NaN              NaN  \n4               NaN           NaN                  NaN              NaN  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>country_code</th>\n      <th>country_name</th>\n      <th>year</th>\n      <th>month</th>\n      <th>monthly_anomaly</th>\n      <th>monthly_unc</th>\n      <th>annual_anomaly</th>\n      <th>annual_unc</th>\n      <th>five_year_anomaly</th>\n      <th>five_year_unc</th>\n      <th>ten_year_anomaly</th>\n      <th>ten_year_unc</th>\n      <th>twenty_year_anomaly</th>\n      <th>twenty_year_unc</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>AFG</td>\n      <td>Afghanistan</td>\n      <td>1848</td>\n      <td>5</td>\n      <td>-0.297</td>\n      <td>2.037</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>AFG</td>\n      <td>Afghanistan</td>\n      <td>1848</td>\n      <td>6</td>\n      <td>-0.796</td>\n      <td>2.136</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>AFG</td>\n      <td>Afghanistan</td>\n      <td>1848</td>\n      <td>7</td>\n      <td>-0.113</td>\n      <td>1.937</td>\n      <td>-0.777</td>\n      <td>0.639</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>AFG</td>\n      <td>Afghanistan</td>\n      <td>1848</td>\n      <td>8</td>\n      <td>-0.462</td>\n      <td>1.937</td>\n      <td>-0.743</td>\n      <td>0.644</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>AFG</td>\n      <td>Afghanistan</td>\n      <td>1848</td>\n      <td>9</td>\n      <td>-1.272</td>\n      <td>1.865</td>\n      <td>-0.676</td>\n      <td>0.669</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_land_country_column_names = [\"country_code\", \"country_name\", \"year\", \"month\", \"monthly_anomaly\", \"monthly_unc\", \"annual_anomaly\",\n",
    "                                  \"annual_unc\", \"five_year_anomaly\", \"five_year_unc\", \"ten_year_anomaly\", \"ten_year_unc\", \"twenty_year_anomaly\", \"twenty_year_unc\"]\n",
    "\n",
    "temp_land_country = pd.DataFrame(columns=temp_land_country_column_names)\n",
    "\n",
    "temp_country_names = temp_countries['Country']\n",
    "\n",
    "# Todo when combining use the dictionary in the data-integration notebook\n",
    "new_country_names = {\n",
    "    \"Denmark (Europe)\": \"Denmark\",\n",
    "    \"France (Europe)\": \"France\",\n",
    "    \"Netherlands (Europe)\": \"Netherlands\",\n",
    "    \"United Kingdom (Europe)\": \"United Kingdom\",\n",
    "    \"Åland\": \"Åland Islands\",\n",
    "    \"Czech Republic\": \"Czechia\",\n",
    "    \"Turkey\": \"Türkiye\",\n",
    "    \"Svalbard and Jan Mayen\": \"Svalbard and Jan Mayen Islands\",\n",
    "    \"Cape Verde\": \"Cabo Verde\",\n",
    "    \"Turks and Caicas Islands\": \"Turks and Caicos Islands\",\n",
    "    \"Swaziland\": \"Eswatini\",\n",
    "    \"Macedonia\": \"North Macedonia\",\n",
    "    \"Côte d'Ivoire\": \"Côte d’Ivoire\",\n",
    "    \"Federated States of Micronesia\": \"Micronesia (Federated States of)\",\n",
    "    \"South Georgia and the South Sandwich Isla\": \"South Georgia and the South Sandwich Islands\",\n",
    "    \"Bonaire, Saint Eustatius and Saba\": \"Bonaire, Sint Eustatius and Saba\",\n",
    "    \"Congo (Democratic Republic of the)\": \"Democratic Republic of the Congo\",\n",
    "    \"South Korea\": \"Korea, South\",\n",
    "    \"North Korea\": \"Korea, North\",\n",
    "    \"Palestina\": \"State of Palestine\"\n",
    "}\n",
    "\n",
    "def swap_keys_values(d):\n",
    "    return {v: k for k, v in d.items()}\n",
    "\n",
    "map_country_to_filename = swap_keys_values(new_country_names)\n",
    "\n",
    "for temp_country_name in temp_country_names:\n",
    "    temp_country_file_name = temp_country_name\n",
    "    if temp_country_name in map_country_to_filename:\n",
    "        temp_country_file_name = map_country_to_filename[temp_country_name]\n",
    "    path_temp_country_txt_file = PATH_RAW_TEMP_DATA_FOLDER + PATH_COUNTRIES_LAND_FOLDER + temp_country_file_name + '.txt'\n",
    "    temp_land_one_country = pd.read_csv(path_temp_country_txt_file, comment=\"%\", header=None, delim_whitespace=True)\n",
    "    country_iso_name = temp_countries.loc[temp_countries['Country'] == temp_country_name]['ISO-alpha3'].iloc[0]\n",
    "\n",
    "    temp_land_one_country.insert(0, 'country_code', country_iso_name)\n",
    "    temp_land_one_country.insert(1, 'country_name', temp_country_name)\n",
    "\n",
    "    temp_land_one_country.columns=temp_land_country_column_names\n",
    "\n",
    "    temp_land_country = pd.concat([temp_land_country, temp_land_one_country])\n",
    "\n",
    "temp_land_country.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Create temp-land-region data from temp-land-country data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The region datasets get created from the temp-and-country dataset."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "outputs": [],
   "source": [
    "def calc_region_anomaly(temp_land_country_regions):\n",
    "    temp_return_land_region = temp_land_country_regions.groupby(['region_code', 'region_name', 'year', 'month'], as_index=False)['monthly_anomaly'].mean()\n",
    "    temp_return_land_region.rename({ 'monthly_anomaly': 'temperature_anomaly'}, axis=1,inplace=True)\n",
    "    return temp_return_land_region"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "outputs": [],
   "source": [
    "# Todo: only load UN country codes once after comnining notebook\n",
    "# load and format un-country-codes data\n",
    "un_country_codes = pd.read_csv(PATH_UN_COUNTRY_CODES_FILE, sep=\";\")\n",
    "un_country_codes = un_country_codes[['Region Code', 'Region Name', 'ISO-alpha3 Code']]\n",
    "un_country_codes.columns=['region_code', 'region_name', 'country_code']\n",
    "\n",
    "# Join UN country codes to temp data\n",
    "# exclude temp data for antarctica when calculating regional temp data\n",
    "temp_land_country_no_antarctica = temp_land_country[temp_land_country.country_name != 'Antarctica']\n",
    "temp_land_country_regions = pd.merge(temp_land_country_no_antarctica, un_country_codes, on='country_code', how='left')\n",
    "temp_land_country_regions.loc[temp_land_country_regions['country_name']=='Taiwan','region_name'] = 'Asia'\n",
    "temp_land_country_regions.loc[temp_land_country_regions['country_name']=='Taiwan','region_code'] = 142\n",
    "\n",
    "# calculate anomaly data for regions\n",
    "temp_land_region = calc_region_anomaly(temp_land_country_regions)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Load berkleys regional data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "outputs": [],
   "source": [
    "temp_land_country_column_names = [\"region_name\", \"year\", \"month\", \"monthly_anomaly\", \"monthly_unc\", \"annual_anomaly\", \"annual_unc\", \"five_year_anomaly\", \"five_year_unc\", \"ten_year_anomaly\", \"ten_year_unc\", \"twenty_year_anomaly\", \"twenty_year_unc\"]\n",
    "temp_berkley_regions = ['Africa', 'Asia', 'Europe', 'North America', 'Oceania', 'South America']\n",
    "temp_berkleys_land_region = pd.DataFrame(columns=temp_land_country_column_names)\n",
    "\n",
    "# Todo: avoid for loop, change to aggregator function\n",
    "for temp_berkley_region in temp_berkley_regions:\n",
    "    region_file_name = temp_berkley_region\n",
    "    path = PATH_RAW_TEMP_DATA_FOLDER + PATH_REGIONS_LAND_FOLDER + region_file_name + '.txt'\n",
    "    one_region = pd.read_csv(path, comment=\"%\", header=None, delim_whitespace=True)\n",
    "\n",
    "    one_region.insert(0, 'region_name', temp_berkley_region)\n",
    "    one_region.columns=temp_land_country_column_names\n",
    "\n",
    "    temp_berkleys_land_region = pd.concat([temp_berkleys_land_region, one_region])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load temp-land-ocean-global data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Two versions exist that treat temperature anomalies at locations with sea ice:\n",
    "1. Anomalies are extrapolated from land-surface air temperature anomalies.\n",
    "2. Anomalies are extrapolated from sea-surface water temperature anomalies (usually collected from open water areas on the periphery of the sea ice).\n",
    "\n",
    "We choose to use the air temperature version based on Berkleys remark:\n",
    "\"We believe that the use of air temperatures above sea ice provides a more natural means of describing changes in Earth's surface temperature.\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "outputs": [],
   "source": [
    "path_global_land_ocean_file = 'global-land-ocean.txt'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "outputs": [],
   "source": [
    "# only include the dataset where anomalies are extrapolated from land-surface air temperature anomalies.\n",
    "temp_land_ocean_global = pd.read_csv(PATH_RAW_TEMP_DATA_FOLDER + path_global_land_ocean_file, comment=\"%\", header=None, delim_whitespace=True, engine='python', skipfooter=2079)\n",
    "temp_land_ocean_global.columns = [\"year\", \"month\", \"monthly_anomaly\", \"monthly_unc\", \"annual_anomaly\", \"annual_unc\", \"five_year_anomaly\", \"five_year_unc\", \"ten_year_anomaly\", \"ten_year_unc\", \"twenty_year_anomaly\", \"twenty_year_unc\"]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Format the data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We only keep entries after the year 1900"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "outputs": [],
   "source": [
    "def cut_before_1900(temp_data):\n",
    "    return temp_data[temp_data['year'] >= 1900]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We only keep monthly anomaly data and rename the column to temperature_anomaly"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "outputs": [],
   "source": [
    "def keep_monthly_anomalies(temp_data):\n",
    "    drop_labels = [\"monthly_unc\", \"annual_anomaly\", \"annual_unc\", \"five_year_anomaly\", \"five_year_unc\", \"ten_year_anomaly\", \"ten_year_unc\", \"twenty_year_anomaly\", \"twenty_year_unc\"]\n",
    "    temp_data = temp_data.drop(labels=drop_labels, axis=1)\n",
    "    return temp_data.rename(columns={'monthly_anomaly': 'temperature_anomaly'})"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Format temp-land-country"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "outputs": [],
   "source": [
    "temp_land_country = cut_before_1900(temp_land_country)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Format temp-land-region and berkleys regional data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "outputs": [],
   "source": [
    "temp_land_region = cut_before_1900(temp_land_region)\n",
    "temp_berkleys_land_region = cut_before_1900(temp_berkleys_land_region)\n",
    "temp_berkleys_land_region = keep_monthly_anomalies(temp_berkleys_land_region)\n",
    "\n",
    "# Todo: format berkleys North & South American data to UN America data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Format temp-land-ocean-global"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "outputs": [],
   "source": [
    "temp_land_ocean_global = cut_before_1900(temp_land_ocean_global)\n",
    "temp_land_ocean_global = keep_monthly_anomalies(temp_land_ocean_global)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Compare berkleys and our regional data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "outputs": [],
   "source": [
    "def temp_calc_region_corr(temp_single_region):\n",
    "    temp_land_single_region = temp_land_region[(temp_land_region['region_name'] == temp_single_region)].set_index(['year', 'month'])\n",
    "    temp_berkleys_land_single_region = temp_berkleys_land_region[(temp_berkleys_land_region['region_name'] == temp_single_region)].set_index(['year', 'month'])\n",
    "\n",
    "    comp_temp_land_africa_joined = temp_berkleys_land_single_region.join(temp_land_single_region, on=['year', 'month'], lsuffix='_berkleys', rsuffix='_self')\n",
    "\n",
    "    temp_land_region_corr = comp_temp_land_africa_joined['temperature_anomaly_berkleys'].corr(comp_temp_land_africa_joined['temperature_anomaly_self'])\n",
    "\n",
    "    print('Correlation for region ' + temp_single_region + ' ' + str(temp_land_region_corr))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Correlation of temperature anomalies between our and berkleys regional temp data sets"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation for region Africa 0.9706252186825862\n",
      "Correlation for region Asia 0.6557149670319498\n",
      "Correlation for region Europe 0.9850257827303103\n",
      "Correlation for region Oceania 0.5959564544896369\n"
     ]
    }
   ],
   "source": [
    "temp_calc_region_corr('Africa')\n",
    "temp_calc_region_corr('Asia')\n",
    "temp_calc_region_corr('Europe')\n",
    "temp_calc_region_corr('Oceania')\n",
    "\n",
    "# Todo: also compare Berkleys america data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Save the data as csv files"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "outputs": [],
   "source": [
    "temp_land_country.to_csv(PATH_PROCESSED_TEMP_DATA_FOLDER + 'temp-land-country.csv', index=False)\n",
    "temp_land_region.to_csv(PATH_PROCESSED_TEMP_DATA_FOLDER + 'temp-land-region.csv', index=False)\n",
    "temp_land_ocean_global.to_csv(PATH_PROCESSED_TEMP_DATA_FOLDER + 'temp-land-ocean-global.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
