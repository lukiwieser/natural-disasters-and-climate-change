{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load and format the temperature anomaly data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "path_raw_temp_data = 'data/raw/temperature/'\n",
    "path_processed_temp_data = 'data/processed/temperature/'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "path_countries_land_files = 'countries-land/'\n",
    "path_countries_list_file = 'temp-countries-list.csv'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Country ISO-alpha3\n",
      "0       Afghanistan        AFG\n",
      "1     Åland Islands        ALA\n",
      "2           Albania        ALB\n",
      "3           Algeria        DZA\n",
      "4    American Samoa        ASM\n",
      "..              ...        ...\n",
      "228  Virgin Islands        VIR\n",
      "229  Western Sahara        ESH\n",
      "230           Yemen        YEM\n",
      "231          Zambia        ZMB\n",
      "232        Zimbabwe        ZWE\n",
      "\n",
      "[233 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Todo: remove loading temp_countries from processed data when combining jupyter notebooks\n",
    "temp_countries: pd.DataFrame = pd.read_csv(path_processed_temp_data+path_countries_list_file,sep=',')\n",
    "print(temp_countries)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load temp-land-country data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "text/plain": "  country_code country_name  year month  monthly_anomaly  monthly_unc  \\\n0          AFG  Afghanistan  1848     5           -0.297        2.037   \n1          AFG  Afghanistan  1848     6           -0.796        2.136   \n2          AFG  Afghanistan  1848     7           -0.113        1.937   \n3          AFG  Afghanistan  1848     8           -0.462        1.937   \n4          AFG  Afghanistan  1848     9           -1.272        1.865   \n\n   annual_anomaly  annual_unc  five_year_anomaly  five_year_unc  \\\n0             NaN         NaN                NaN            NaN   \n1             NaN         NaN                NaN            NaN   \n2          -0.777       0.639                NaN            NaN   \n3          -0.743       0.644                NaN            NaN   \n4          -0.676       0.669                NaN            NaN   \n\n   ten_year_anomaly  ten_year_unc  twenty_year_anomaly  twenty_year_unc  \n0               NaN           NaN                  NaN              NaN  \n1               NaN           NaN                  NaN              NaN  \n2               NaN           NaN                  NaN              NaN  \n3               NaN           NaN                  NaN              NaN  \n4               NaN           NaN                  NaN              NaN  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>country_code</th>\n      <th>country_name</th>\n      <th>year</th>\n      <th>month</th>\n      <th>monthly_anomaly</th>\n      <th>monthly_unc</th>\n      <th>annual_anomaly</th>\n      <th>annual_unc</th>\n      <th>five_year_anomaly</th>\n      <th>five_year_unc</th>\n      <th>ten_year_anomaly</th>\n      <th>ten_year_unc</th>\n      <th>twenty_year_anomaly</th>\n      <th>twenty_year_unc</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>AFG</td>\n      <td>Afghanistan</td>\n      <td>1848</td>\n      <td>5</td>\n      <td>-0.297</td>\n      <td>2.037</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>AFG</td>\n      <td>Afghanistan</td>\n      <td>1848</td>\n      <td>6</td>\n      <td>-0.796</td>\n      <td>2.136</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>AFG</td>\n      <td>Afghanistan</td>\n      <td>1848</td>\n      <td>7</td>\n      <td>-0.113</td>\n      <td>1.937</td>\n      <td>-0.777</td>\n      <td>0.639</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>AFG</td>\n      <td>Afghanistan</td>\n      <td>1848</td>\n      <td>8</td>\n      <td>-0.462</td>\n      <td>1.937</td>\n      <td>-0.743</td>\n      <td>0.644</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>AFG</td>\n      <td>Afghanistan</td>\n      <td>1848</td>\n      <td>9</td>\n      <td>-1.272</td>\n      <td>1.865</td>\n      <td>-0.676</td>\n      <td>0.669</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_names = [\"country_code\", \"country_name\", \"year\", \"month\", \"monthly_anomaly\", \"monthly_unc\", \"annual_anomaly\", \"annual_unc\", \"five_year_anomaly\", \"five_year_unc\", \"ten_year_anomaly\", \"ten_year_unc\", \"twenty_year_anomaly\", \"twenty_year_unc\"]\n",
    "\n",
    "temp_land_country = pd.DataFrame(columns=column_names)\n",
    "\n",
    "country_names = temp_countries['Country']\n",
    "\n",
    "# Todo when combining use the dictionary in the data-integration notebook\n",
    "new_country_names = {\n",
    "    \"Denmark (Europe)\": \"Denmark\",\n",
    "    \"France (Europe)\": \"France\",\n",
    "    \"Netherlands (Europe)\": \"Netherlands\",\n",
    "    \"United Kingdom (Europe)\": \"United Kingdom\",\n",
    "    \"Åland\": \"Åland Islands\",\n",
    "    \"Czech Republic\": \"Czechia\",\n",
    "    \"Turkey\": \"Türkiye\",\n",
    "    \"Svalbard and Jan Mayen\": \"Svalbard and Jan Mayen Islands\",\n",
    "    \"Cape Verde\": \"Cabo Verde\",\n",
    "    \"Turks and Caicas Islands\": \"Turks and Caicos Islands\",\n",
    "    \"Swaziland\": \"Eswatini\",\n",
    "    \"Macedonia\": \"North Macedonia\",\n",
    "    \"Côte d'Ivoire\": \"Côte d’Ivoire\",\n",
    "    \"Federated States of Micronesia\": \"Micronesia (Federated States of)\",\n",
    "    \"South Georgia and the South Sandwich Isla\": \"South Georgia and the South Sandwich Islands\",\n",
    "    \"Bonaire, Saint Eustatius and Saba\": \"Bonaire, Sint Eustatius and Saba\",\n",
    "    \"Congo (Democratic Republic of the)\": \"Democratic Republic of the Congo\",\n",
    "    \"South Korea\": \"Korea, South\",\n",
    "    \"North Korea\": \"Korea, North\",\n",
    "    \"Palestina\": \"State of Palestine\"\n",
    "}\n",
    "\n",
    "def swap_keys_values(d):\n",
    "    return {v: k for k, v in d.items()}\n",
    "\n",
    "map_country_to_filename = swap_keys_values(new_country_names)\n",
    "\n",
    "for country_name in country_names:\n",
    "    country_file_name = country_name\n",
    "    if country_name in map_country_to_filename:\n",
    "        country_file_name = map_country_to_filename[country_name]\n",
    "    path = path_raw_temp_data + path_countries_land_files + country_file_name + '.txt'\n",
    "    one_country = pd.read_csv(path, comment=\"%\", header=None, delim_whitespace=True)\n",
    "    iso_name = temp_countries.loc[temp_countries['Country'] == country_name]['ISO-alpha3'].iloc[0]\n",
    "\n",
    "    one_country.insert(0, 'country_code', iso_name)\n",
    "    one_country.insert(1, 'country_name', country_name)\n",
    "\n",
    "    one_country.columns=column_names\n",
    "\n",
    "    temp_land_country = pd.concat([temp_land_country, one_country])\n",
    "\n",
    "# exclude antarctica\n",
    "temp_land_country = temp_land_country[temp_land_country.country_name != 'Antarctica']\n",
    "\n",
    "temp_land_country.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Create temp-land-region data from temp-land-country data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The region datasets get created from the temp-and-country dataset."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "def calc_region_anomaly(temp_land_country_regions):\n",
    "    regions = temp_land_country_regions[['region_code', 'region_name']].drop_duplicates()\n",
    "    rows=[]\n",
    "    for region_name in regions['region_name']:\n",
    "        temp_land_country_single_region = temp_land_country_regions[temp_land_country_regions['region_name']==region_name]\n",
    "        min_year = min(temp_land_country_regions['year'])\n",
    "        for year in range(min_year, 2023):\n",
    "            temp_land_country_single_region_year = temp_land_country_single_region[temp_land_country_single_region['year']==year]\n",
    "            for month in range(1, 13):\n",
    "                temp_land_country_single_region_year_month=temp_land_country_single_region_year[temp_land_country_single_region_year['month']==month]\n",
    "                monthly_anomaly = temp_land_country_single_region_year_month['monthly_anomaly'].mean()\n",
    "                new_row = {\n",
    "                    'region_code': regions[regions['region_name']==region_name].region_code.item(),\n",
    "                    'region_name': region_name,\n",
    "                    'year': year,\n",
    "                    'month': month,\n",
    "                    'temperature_anomaly': monthly_anomaly\n",
    "                }\n",
    "                rows.append(new_row)\n",
    "    return pd.DataFrame.from_dict(rows, orient='columns')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "# load and format un-country-codes data\n",
    "path_un_country_codes = \"data/raw/country-codes/un-country-codes.csv\"\n",
    "un_country_codes = pd.read_csv(path_un_country_codes, sep=\";\")\n",
    "un_country_codes_drop_labels=['Global Code', 'Global Name', 'Sub-region Code', 'Sub-region Name', 'Intermediate Region Code', 'Intermediate Region Name',\n",
    "                              'Country or Area', 'M49 Code', 'ISO-alpha2 Code', 'Least Developed Countries (LDC)',\n",
    "                              'Land Locked Developing Countries (LLDC)', 'Small Island Developing States (SIDS)']\n",
    "un_country_codes.drop(labels=un_country_codes_drop_labels, axis=1 ,inplace=True)\n",
    "un_country_codes.columns=['region_code', 'region_name', 'country_code']\n",
    "\n",
    "# Join UN country codes to temp data\n",
    "temp_land_country_regions = pd.merge(temp_land_country, un_country_codes, on='country_code', how='left')\n",
    "temp_land_country_regions.loc[temp_land_country_regions['country_name']=='Taiwan','region_name'] = 'Asia'\n",
    "temp_land_country_regions.loc[temp_land_country_regions['country_name']=='Taiwan','region_code'] = 142\n",
    "\n",
    "# calculate anomaly data for regions\n",
    "temp_land_region = calc_region_anomaly(temp_land_country_regions)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Load berkleys regional data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "column_names = [\"region_name\", \"year\", \"month\", \"monthly_anomaly\", \"monthly_unc\", \"annual_anomaly\", \"annual_unc\", \"five_year_anomaly\", \"five_year_unc\", \"ten_year_anomaly\", \"ten_year_unc\", \"twenty_year_anomaly\", \"twenty_year_unc\"]\n",
    "regions = ['Africa', 'Asia', 'Europe', 'North America', 'Oceania', 'South America']\n",
    "path_regions_land_files = 'regions-land/'\n",
    "temp_berkleys_land_region = pd.DataFrame(columns=column_names)\n",
    "for region in regions:\n",
    "    region_file_name = region\n",
    "    path = path_raw_temp_data + path_regions_land_files + region_file_name + '.txt'\n",
    "    one_region = pd.read_csv(path, comment=\"%\", header=None, delim_whitespace=True)\n",
    "\n",
    "    one_region.insert(0, 'region_name', region)\n",
    "    one_region.columns=column_names\n",
    "\n",
    "    temp_berkleys_land_region = pd.concat([temp_berkleys_land_region, one_region])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load temp-land-ocean-global data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Two versions exist that treat temperature anomalies at locations with sea ice:\n",
    "1. Anomalies are extrapolated from land-surface air temperature anomalies.\n",
    "2. Anomalies are extrapolated from sea-surface water temperature anomalies (usually collected from open water areas on the periphery of the sea ice).\n",
    "\n",
    "We choose to use the air temperature version based on Berkleys remark:\n",
    "\"We believe that the use of air temperatures above sea ice provides a more natural means of describing changes in Earth's surface temperature.\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "path_global_land_ocean_file = 'global-land-ocean.txt'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "# only include the dataset where anomalies are extrapolated from land-surface air temperature anomalies.\n",
    "temp_land_ocean_global = pd.read_csv(path_raw_temp_data + path_global_land_ocean_file, comment=\"%\", header=None, delim_whitespace=True, engine='python', skipfooter=2079)\n",
    "temp_land_ocean_global.columns = [\"year\", \"month\", \"monthly_anomaly\", \"monthly_unc\", \"annual_anomaly\", \"annual_unc\", \"five_year_anomaly\", \"five_year_unc\", \"ten_year_anomaly\", \"ten_year_unc\", \"twenty_year_anomaly\", \"twenty_year_unc\"]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Format the data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We only keep entries after the year 1900"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "def cut_before_1900(temp_data):\n",
    "    return temp_data[temp_data['year'] >= 1900]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We only keep monthly anomaly data and rename the column to temperature_anomaly"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "def keep_monthly_anomalies(temp_data):\n",
    "    drop_labels = [\"monthly_unc\", \"annual_anomaly\", \"annual_unc\", \"five_year_anomaly\", \"five_year_unc\", \"ten_year_anomaly\", \"ten_year_unc\", \"twenty_year_anomaly\", \"twenty_year_unc\"]\n",
    "    temp_data = temp_data.drop(labels=drop_labels, axis=1)\n",
    "    return temp_data.rename(columns={'monthly_anomaly': 'temperature_anomaly'})"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Format temp-land-country"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "temp_land_country = cut_before_1900(temp_land_country)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Format temp-land-region and berkleys"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "temp_land_region = cut_before_1900(temp_land_region)\n",
    "temp_berkleys_land_region = cut_before_1900(temp_berkleys_land_region)\n",
    "temp_berkleys_land_region = keep_monthly_anomalies(temp_berkleys_land_region)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Format temp-land-ocean-global"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "temp_land_ocean_global = cut_before_1900(temp_land_ocean_global)\n",
    "temp_land_ocean_global = keep_monthly_anomalies(temp_land_ocean_global)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Compare berkleys and our regional data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [],
   "source": [
    "def calc_temp_region_corr(region):\n",
    "    comp_temp_land_region = temp_land_region[(temp_land_region['region_name']==region)].set_index(['year', 'month'])\n",
    "    comp_temp_berkleys_land_region = temp_berkleys_land_region[(temp_berkleys_land_region['region_name']==region)].set_index(['year', 'month'])\n",
    "\n",
    "    comp_temp_land_africa_joined = comp_temp_berkleys_land_region.join(comp_temp_land_region, on=['year', 'month'], lsuffix='_berkleys', rsuffix='_self')\n",
    "\n",
    "    corr = comp_temp_land_africa_joined['temperature_anomaly_berkleys'].corr(comp_temp_land_africa_joined['temperature_anomaly_self'])\n",
    "\n",
    "    print('Correlation for region ' + region + ' ' + str(corr))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Correlation of temperature anomalies between our and berkleys regional temp data sets"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation for region Africa 0.9706252186825862\n",
      "Correlation for region Asia 0.6557149670319498\n",
      "Correlation for region Europe 0.9850257827303103\n"
     ]
    }
   ],
   "source": [
    "calc_temp_region_corr('Africa')\n",
    "calc_temp_region_corr('Asia')\n",
    "calc_temp_region_corr('Europe')\n",
    "calc_temp_region_corr('Oceania')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Save the data as csv files"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "temp_land_country.to_csv(path_processed_temp_data+'temp-land-country.csv',index=False)\n",
    "temp_land_region.to_csv(path_processed_temp_data+'temp-land-region.csv',index=False)\n",
    "temp_land_ocean_global.to_csv(path_processed_temp_data+'temp-land-ocean-global.csv',index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
